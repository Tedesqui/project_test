<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <title>Corre√ß√£o de Provas AR + OCR + ChatGPT</title>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5.0.1/dist/tesseract.min.js"></script>

  <style>
    body, html {
      margin: 0;
      padding: 0;
      font-family: sans-serif;
      background: black;
      color: white;
      overflow: hidden;
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }
    #output {
      position: fixed;
      bottom: 0;
      width: 100%;
      background: rgba(0,0,0,0.8);
      padding: 10px;
      font-size: 16px;
      z-index: 2;
      max-height: 40vh;
      overflow-y: auto;
    }
    #controls {
      position: fixed;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 3;
      display: flex;
      gap: 10px;
    }
    button {
      font-size: 16px;
      padding: 10px 16px;
      background: #0d6efd;
      border: none;
      border-radius: 8px;
      color: white;
      cursor: pointer;
    }
    button:hover {
      background: #0056b3;
    }
  </style>
</head>
<body>

<video id="video" autoplay playsinline muted></video>
<canvas id="canvas" width="640" height="480" style="display:none;"></canvas>

<div id="controls">
  <button id="zoomBtn" onclick="toggleZoom()">üîç Zoom: 1x</button>
  <button onclick="captureAndAnalyze()">üì∑ Corrigir</button>
</div>

<div id="output">üì∑ Aponte a c√¢mera para a resposta da prova e toque em "Corrigir"</div>

<script>
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  const output = document.getElementById("output");
  const zoomBtn = document.getElementById("zoomBtn");

  let mediaTrack;
  let currentZoom = 1;
  const zoomLevels = [1, 2, 3];

  async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: { exact: "environment" },
        width: { ideal: 640 },
        height: { ideal: 480 }
      }
    });
    video.srcObject = stream;
    mediaTrack = stream.getVideoTracks()[0];
  }

  async function toggleZoom() {
    if (mediaTrack && mediaTrack.getCapabilities) {
      const caps = mediaTrack.getCapabilities();
      if (caps.zoom) {
        const currentIndex = zoomLevels.indexOf(currentZoom);
        currentZoom = zoomLevels[(currentIndex + 1) % zoomLevels.length];

        await mediaTrack.applyConstraints({ advanced: [{ zoom: currentZoom }] });
        zoomBtn.innerText = `üîç Zoom: ${currentZoom}x`;
        output.innerText = `üîç Zoom atual: ${currentZoom}x`;
      } else {
        output.innerText = "‚ö†Ô∏è Zoom n√£o suportado neste dispositivo.";
      }
    }
  }

  async function captureAndAnalyze() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    output.innerText = "üß† Lendo resposta com OCR...";

    const { data: { text } } = await Tesseract.recognize(canvas, 'por', {
      logger: m => console.log(m)
    });

    output.innerText = "üîé Texto detectado:\n" + text + "\n\nEnviando para IA...";

    // Chamada para backend seguro na Vercel
    const response = await fetch("https://SEU-BACKEND.vercel.app/api/corrigir", {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ texto: text })
    });

    const data = await response.json();
    output.innerText = "‚úÖ Corre√ß√£o:\n" + data.resultado;
  }

  startCamera();
</script>

</body>
</html>
